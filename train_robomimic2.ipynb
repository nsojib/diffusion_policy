{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# use line-buffering for both stdout and stderr\n",
    "# sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1)\n",
    "# sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1)\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "import pathlib\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    " \n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "# from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.robomimic_lowdim_policy import RobomimicLowdimPolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "from diffusion_policy.env_runner.base_lowdim_runner import BaseLowdimRunner\n",
    "from diffusion_policy.common.checkpoint_util import TopKCheckpointManager\n",
    "from diffusion_policy.common.json_logger import JsonLogger\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "\n",
    "from diffusion_policy.policy.robomimic_lowdim_policy import RobomimicLowdimPolicy\n",
    "from diffusion_policy.policy.robomimic_image_policy import RobomimicImagePolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "\n",
    "# from diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace import TrainDiffusionUnetHybridWorkspace\n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.diffusion_unet_hybrid_image_policy import DiffusionUnetHybridImagePolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "from diffusion_policy.common.checkpoint_util import TopKCheckpointManager\n",
    "from diffusion_policy.common.json_logger import JsonLogger\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "from diffusion_policy.model.diffusion.ema_model import EMAModel\n",
    "from diffusion_policy.model.common.lr_scheduler import get_scheduler\n",
    "\n",
    "from diffusion_policy.dataset.robomimic_replay_image_dataset import RobomimicReplayImageDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Sampler \n",
    "\n",
    "import h5py\n",
    "\n",
    "# import mimicgen\n",
    "# import mimicgen.utils.file_utils as MG_FileUtils\n",
    "# import mimicgen.utils.robomimic_utils as RobomimicUtils\n",
    "# from mimicgen.utils.misc_utils import add_red_border_to_frame\n",
    "# from mimicgen.configs import MG_TaskSpec\n",
    "\n",
    "OmegaConf.register_new_resolver(\"eval\", eval, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='.'\n",
    "# config_name = 'image_square_mh_diffusion_policy_cnn_worse_uid.yaml'\n",
    "config_name = \"image_square_mh_diffusion_policy_cnn_g40b30.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace.TrainDiffusionUnetHybridWorkspace', 'checkpoint': {'save_last_ckpt': True, 'save_last_snapshot': False, 'topk': {'format_str': 'epoch={epoch:04d}-test_mean_score={test_mean_score:.3f}.ckpt', 'k': 5, 'mode': 'max', 'monitor_key': 'test_mean_score'}}, 'dataloader': {'batch_size': 64, 'num_workers': 8, 'persistent_workers': False, 'pin_memory': True, 'shuffle': True}, 'dataset_obs_steps': 2, 'ema': {'_target_': 'diffusion_policy.model.diffusion.ema_model.EMAModel', 'inv_gamma': 1.0, 'max_value': 0.9999, 'min_value': 0.0, 'power': 0.75, 'update_after_step': 0}, 'exp_name': 'default', 'horizon': 16, 'keypoint_visible_rate': 1.0, 'logging': {'group': None, 'id': None, 'mode': 'online', 'name': '2022.12.29-22.31.41_train_diffusion_unet_hybrid_square_image', 'project': 'diffusion_policy_debug', 'resume': True, 'tags': ['train_diffusion_unet_hybrid', 'square_image', 'default']}, 'multi_run': {'run_dir': 'data/outputs/2022.12.29/22.31.41_train_diffusion_unet_hybrid_square_image', 'wandb_name_base': '2022.12.29-22.31.41_train_diffusion_unet_hybrid_square_image'}, 'n_action_steps': 8, 'n_latency_steps': 0, 'n_obs_steps': 2, 'name': 'train_diffusion_unet_hybrid', 'obs_as_global_cond': True, 'optimizer': {'_target_': 'torch.optim.AdamW', 'betas': [0.95, 0.999], 'eps': 1e-08, 'lr': 0.0001, 'weight_decay': 1e-06}, 'past_action_visible': False, 'policy': {'_target_': 'diffusion_policy.policy.diffusion_unet_hybrid_image_policy.DiffusionUnetHybridImagePolicy', 'cond_predict_scale': True, 'crop_shape': [76, 76], 'diffusion_step_embed_dim': 128, 'down_dims': [512, 1024, 2048], 'eval_fixed_crop': True, 'horizon': 16, 'kernel_size': 5, 'n_action_steps': 8, 'n_groups': 8, 'n_obs_steps': 2, 'noise_scheduler': {'_target_': 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler', 'beta_end': 0.02, 'beta_schedule': 'squaredcos_cap_v2', 'beta_start': 0.0001, 'clip_sample': True, 'num_train_timesteps': 100, 'prediction_type': 'epsilon', 'variance_type': 'fixed_small'}, 'num_inference_steps': 100, 'obs_as_global_cond': True, 'obs_encoder_group_norm': True, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_gripper_qpos': {'shape': [2]}}}}, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_gripper_qpos': {'shape': [2]}}}, 'task': {'abs_action': True, 'dataset': {'_target_': 'diffusion_policy.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset', 'abs_action': True, 'dataset_path': '/home/carl_lab/dataset_mimicgen/square134_2_g40b30_abs.hdf5', 'horizon': 16, 'n_obs_steps': 2, 'pad_after': 7, 'pad_before': 1, 'rotation_rep': 'rotation_6d', 'seed': 42, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_gripper_qpos': {'shape': [2]}}}, 'use_cache': True, 'val_ratio': 0.02}, 'dataset_path': '/home/carl_lab/dataset_mimicgen/square134_2_g40b30_abs.hdf5', 'dataset_type': 'mh', 'env_runner': {'_target_': 'diffusion_policy.env_runner.robomimic_image_runner.RobomimicImageRunner', 'abs_action': True, 'crf': 22, 'dataset_path': '/home/carl_lab/dataset_mimicgen/square134_2_g40b30_abs.hdf5', 'fps': 10, 'max_steps': 500, 'n_action_steps': 8, 'n_envs': 28, 'n_obs_steps': 2, 'n_test': 50, 'n_test_vis': 4, 'n_train': 6, 'n_train_vis': 2, 'past_action': False, 'render_obs_key': 'agentview_image', 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_gripper_qpos': {'shape': [2]}}}, 'test_start_seed': 100000, 'tqdm_interval_sec': 1.0, 'train_start_idx': 0}, 'name': 'square_image', 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_eef_pos': {'shape': [3]}, 'robot0_eef_quat': {'shape': [4]}, 'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'}, 'robot0_gripper_qpos': {'shape': [2]}}}, 'task_name': 'square'}, 'task_name': 'square_image', 'training': {'checkpoint_every': 50, 'debug': False, 'device': 'cuda:0', 'gradient_accumulate_every': 1, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'max_train_steps': None, 'max_val_steps': None, 'num_epochs': 8000, 'resume': True, 'rollout_every': 50, 'sample_every': 5, 'seed': 42, 'tqdm_interval_sec': 1.0, 'use_ema': True, 'val_every': 10}, 'val_dataloader': {'batch_size': 64, 'num_workers': 8, 'persistent_workers': False, 'pin_memory': True, 'shuffle': False}}\n",
      "resume:  True\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=config_path):\n",
    "    cfg_org = compose(\n",
    "        config_name=config_name,\n",
    "        overrides=[\n",
    "            \"hydra.run.dir=data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}\",\n",
    "            \"training.seed=42\",\n",
    "            \"training.device=cuda:0\"\n",
    "        ],\n",
    "    )\n",
    "    print(cfg_org)\n",
    "    \n",
    "OmegaConf.resolve(cfg_org)\n",
    "\n",
    "print('resume: ', cfg_org.training.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_checkpoint_dir = \"/home/carl_lab/diffusion_policy/data/outputs/2024.12.13/03.05.17_train_diffusion_unet_hybrid_square_image/\"\n",
    "last_checkpoint_dir = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDiffusionUnetHybridWorkspace(BaseWorkspace):\n",
    "    include_keys = ['global_step', 'epoch']\n",
    "\n",
    "    def __init__(self, cfg: OmegaConf, output_dir=None):\n",
    "        super().__init__(cfg, output_dir=output_dir)\n",
    "\n",
    "        # set seed\n",
    "        seed = cfg.training.seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # configure model\n",
    "        self.model: DiffusionUnetHybridImagePolicy = hydra.utils.instantiate(cfg.policy)\n",
    "\n",
    "        self.ema_model: DiffusionUnetHybridImagePolicy = None\n",
    "        if cfg.training.use_ema:\n",
    "            self.ema_model = copy.deepcopy(self.model)\n",
    "\n",
    "        # configure training state\n",
    "        self.optimizer = hydra.utils.instantiate(\n",
    "            cfg.optimizer, params=self.model.parameters())\n",
    "\n",
    "        # configure training state\n",
    "        self.global_step = 0\n",
    "        self.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recreating workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_gripper_qpos', 'robot0_eef_quat', 'robot0_eef_pos']\n",
      "using obs modality: rgb with keys: ['agentview_image', 'robot0_eye_in_hand_image']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carl_lab/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/carl_lab/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion params: 2.556120e+08\n",
      "Vision params: 2.239418e+07\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/home/carl_lab/diffusion_policy/data/outputs/custom\"\n",
    "workspace = TrainDiffusionUnetHybridWorkspace(cfg_org, output_dir=output_dir)\n",
    "\n",
    "self = workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = copy.deepcopy(self.cfg)\n",
    "\n",
    "# resume training\n",
    "# if cfg.training.resume:\n",
    "#     lastest_ckpt_path = self.get_checkpoint_path()\n",
    "#     if lastest_ckpt_path.is_file():\n",
    "#         print(f\"Resuming from checkpoint {lastest_ckpt_path}\")\n",
    "#         self.load_checkpoint(path=lastest_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_config = {key: value for key, value in cfg.task.dataset.items() if key != '_target_'}\n",
    "# dataset = RobomimicReplayImageDataset(**new_config)\n",
    "# len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = OmegaConf.to_container(cfg.task.dataset, resolve=True )\n",
    "del new_config['_target_']\n",
    "new_config['shape_meta']['obs']['demo_no']={'shape':[] }\n",
    "new_config['shape_meta']['obs']['index_in_demo']={'shape':[] }\n",
    "# new_config['use_cache'] = False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abs_action': True,\n",
       " 'dataset_path': '/home/carl_lab/dataset_mimicgen/square134_2_g40b30_abs.hdf5',\n",
       " 'horizon': 16,\n",
       " 'n_obs_steps': 2,\n",
       " 'pad_after': 7,\n",
       " 'pad_before': 1,\n",
       " 'rotation_rep': 'rotation_6d',\n",
       " 'seed': 42,\n",
       " 'shape_meta': {'action': {'shape': [10]},\n",
       "  'obs': {'agentview_image': {'shape': [3, 84, 84], 'type': 'rgb'},\n",
       "   'robot0_eef_pos': {'shape': [3]},\n",
       "   'robot0_eef_quat': {'shape': [4]},\n",
       "   'robot0_eye_in_hand_image': {'shape': [3, 84, 84], 'type': 'rgb'},\n",
       "   'robot0_gripper_qpos': {'shape': [2]},\n",
       "   'demo_no': {'shape': []},\n",
       "   'index_in_demo': {'shape': []}}},\n",
       " 'use_cache': True,\n",
       " 'val_ratio': 0.02}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring lock on cache.\n",
      "Cache does not exist. Creating!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading lowdim data: 100%|██████████| 6/6 [00:00<00:00, 156.75it/s]\n",
      "Loading image data: 100%|██████████| 75368/75368 [00:31<00:00, 2403.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cache to disk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36712"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = RobomimicReplayImageDataset(**new_config, hdf5_filter_key = \"g40b30\")\n",
    "dataset = RobomimicReplayImageDataset(**new_config)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 10]), torch.Size([2, 3, 84, 84]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = dataset.__getitem__(100)\n",
    "dt['action'].shape, dt['obs']['agentview_image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0.]), tensor([ 99., 100.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['obs']['demo_no'], dt['obs']['index_in_demo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_filter_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segs_toremove={\n",
    "#  'demo_0': [ (5,20), (30, 40) ],\n",
    "#  'demo_1': [ (12, 20) ],\n",
    "#  'demo_12': [(0, 10), (15, 20), (30,33) ],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segs_toremove={\n",
    "#  'demo_3': [(199, 730)],\n",
    "#  'demo_4': [(176, 544)],\n",
    "#  'demo_11': [(200, 488)],\n",
    "#  'demo_12': [(0, 404), (405, 780)],\n",
    "#  'demo_13': [(0, 163), (164, 602)],\n",
    "#  'demo_14': [(0, 107), (108, 993)],\n",
    "#  'demo_20': [(177, 979)],\n",
    "#  'demo_21': [(162, 673)],\n",
    "#  'demo_26': [(68, 617)],\n",
    "#  'demo_27': [(211, 662)],\n",
    "#  'demo_28': [(0, 160), (161, 1014)],\n",
    "#  'demo_29': [(218, 1120)],\n",
    "#  'demo_32': [(166, 753)],\n",
    "#  'demo_34': [(191, 968)],\n",
    "#  'demo_35': [(171, 1134)],\n",
    "#  'demo_36': [(153, 735)],\n",
    "#  'demo_37': [(162, 594)],\n",
    "#  'demo_100': [(191, 354)],\n",
    "#  'demo_101': [(0, 321)],\n",
    "#  'demo_102': [(0, 581)],\n",
    "#  'demo_103': [(0, 505)],\n",
    "#  'demo_104': [(0, 412), (413, 644)],\n",
    "#  'demo_105': [(0, 362), (363, 590)],\n",
    "#  'demo_106': [(0, 296)],\n",
    "#  'demo_107': [(58, 715)],\n",
    "#  'demo_108': [(0, 462)],\n",
    "#  'demo_109': [(0, 349)],\n",
    "#  'demo_110': [(0, 476)],\n",
    "#  'demo_111': [(0, 503)],\n",
    "#  'demo_112': [(0, 853), (854, 1083)],\n",
    "#  'demo_113': [(0, 535), (536, 727)],\n",
    "#  'demo_42': [(213, 435)]}\n",
    "\n",
    "#new indexing in the g40b30 file\n",
    "segs_toremove= {\n",
    " 'demo_38': [(199, 730)],\n",
    " 'demo_47': [(176, 544)],\n",
    " 'demo_2': [(200, 488)],\n",
    " 'demo_24': [(0, 404), (405, 780)],\n",
    " 'demo_25': [(0, 163), (164, 602)],\n",
    " 'demo_26': [(0, 107), (108, 993)],\n",
    " 'demo_31': [(177, 979)],\n",
    " 'demo_32': [(162, 673)],\n",
    " 'demo_34': [(68, 617)],\n",
    " 'demo_35': [(211, 662)],\n",
    " 'demo_36': [(0, 160), (161, 1014)],\n",
    " 'demo_37': [(218, 1120)],\n",
    " 'demo_40': [(166, 753)],\n",
    " 'demo_41': [(191, 968)],\n",
    " 'demo_42': [(171, 1134)],\n",
    " 'demo_43': [(153, 735)],\n",
    " 'demo_44': [(162, 594)],\n",
    " 'demo_10': [(191, 354)],\n",
    " 'demo_11': [(0, 321)],\n",
    " 'demo_12': [(0, 581)],\n",
    " 'demo_13': [(0, 505)],\n",
    " 'demo_14': [(0, 412), (413, 644)],\n",
    " 'demo_15': [(0, 362), (363, 590)],\n",
    " 'demo_16': [(0, 296)],\n",
    " 'demo_17': [(58, 715)],\n",
    " 'demo_18': [(0, 462)],\n",
    " 'demo_19': [(0, 349)],\n",
    " 'demo_20': [(0, 476)],\n",
    " 'demo_21': [(0, 503)],\n",
    " 'demo_22': [(0, 853), (854, 1083)],\n",
    " 'demo_23': [(0, 535), (536, 727)],\n",
    " 'demo_49': [(213, 435)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ids={}\n",
    "for key in segs_toremove.keys():\n",
    "    segs = segs_toremove[key]\n",
    "    ids = [] \n",
    "    for start, end in segs:\n",
    "        ids.extend(range(start, end + 1))  # Include the end value\n",
    "\n",
    "    demo_no = int(key.split(\"_\")[1])\n",
    "    remove_ids[demo_no]=ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_ids[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36712/36712 [03:12<00:00, 190.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_indices =[]  #in the dataset.\n",
    "\n",
    "for index in tqdm.tqdm( range(len(dataset)) ):\n",
    "    data = dataset.__getitem__(index)\n",
    "    demo_no =int( data['obs']['demo_no'][0].item() )\n",
    "    indices_in_demo = data['obs']['index_in_demo'].numpy().astype(int)\n",
    " \n",
    "    should_remove = False\n",
    "    if demo_no in remove_ids:\n",
    "        should_remove = bool(set(remove_ids[demo_no]) & set(indices_in_demo))\n",
    "    if should_remove: continue \n",
    "    valid_indices.append(index)\n",
    "\n",
    "len(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomIndicesSampler(Sampler):\n",
    "    def __init__(self, custom_indices):\n",
    "        self.custom_indices = np.random.permutation(custom_indices)\n",
    "\n",
    "    def __iter__(self): \n",
    "        return iter(self.custom_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len( self.custom_indices )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = CustomIndicesSampler(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring lock on cache.\n",
      "Loading cached ReplayBuffer from Disk.\n",
      "Loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36712"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config = OmegaConf.to_container(cfg.task.dataset, resolve=True )\n",
    "del new_config['_target_']\n",
    "# new_config['shape_meta']['obs']['demo_no']={'shape':[] }\n",
    "# new_config['shape_meta']['obs']['index_in_demo']={'shape':[] }\n",
    "\n",
    "\n",
    "dataset = RobomimicReplayImageDataset(**new_config)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dataloader = {key:value for key,value in cfg.dataloader.items()}\n",
    "cfg_dataloader['shuffle']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, **cfg_dataloader, sampler=sampler)\n",
    "normalizer = dataset.get_normalizer()\n",
    "\n",
    "# configure validation dataset\n",
    "val_dataset = dataset.get_validation_dataset()\n",
    "val_dataloader = DataLoader(val_dataset, **cfg.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obs', 'action'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch =  next(iter(train_dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 3, 84, 84])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['obs']['agentview_image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model.set_normalizer(normalizer)\n",
    "if cfg.training.use_ema:\n",
    "    self.ema_model.set_normalizer(normalizer)\n",
    "\n",
    "# configure lr scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    cfg.training.lr_scheduler,\n",
    "    optimizer=self.optimizer,\n",
    "    num_warmup_steps=cfg.training.lr_warmup_steps,\n",
    "    num_training_steps=(\n",
    "        len(train_dataloader) * cfg.training.num_epochs) \\\n",
    "            // cfg.training.gradient_accumulate_every,\n",
    "    # pytorch assumes stepping LRScheduler every epoch\n",
    "    # however huggingface diffusers steps it every batch\n",
    "    last_epoch=self.global_step-1\n",
    ")\n",
    "\n",
    "# configure ema\n",
    "ema: EMAModel = None\n",
    "if cfg.training.use_ema:\n",
    "    ema = hydra.utils.instantiate(\n",
    "        cfg.ema,\n",
    "        model=self.ema_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquareCreated environment with name NutAssemblySquare\n",
      "\n",
      "Action size is 7\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquareCreated environment with name NutAssemblySquareCreated environment with name NutAssemblySquare\n",
      "\n",
      "Action size is 7\n",
      "Action size is 7\n",
      "\n",
      "Action size is 7\n",
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n",
      "Created environment with name NutAssemblySquare\n",
      "Action size is 7\n"
     ]
    }
   ],
   "source": [
    "env_runner: BaseImageRunner\n",
    "env_runner = hydra.utils.instantiate(\n",
    "    cfg.task.env_runner,\n",
    "    output_dir=self.output_dir)\n",
    "assert isinstance(env_runner, BaseImageRunner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.95, 0.999]\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    initial_lr: 0.0001\n",
       "    lr: 0.0\n",
       "    maximize: False\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_manager = TopKCheckpointManager(\n",
    "    save_dir=os.path.join(self.output_dir, 'checkpoints'),\n",
    "    **cfg.checkpoint.topk\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device(cfg.training.device)\n",
    "self.model.to(device)\n",
    "if self.ema_model is not None:\n",
    "    self.ema_model.to(device)\n",
    "optimizer_to(self.optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0:  97%|█████████▋| 379/392 [00:46<00:01,  8.58it/s, loss=0.0586]"
     ]
    }
   ],
   "source": [
    "train_sampling_batch = None\n",
    "log_path = os.path.join(self.output_dir, 'logs.json.txt')\n",
    "with JsonLogger(log_path) as json_logger:\n",
    "    for local_epoch_idx in range(cfg.training.num_epochs):\n",
    "        step_log = dict()\n",
    "        # ========= train for this epoch ==========\n",
    "        train_losses = list()\n",
    "        with tqdm.tqdm(train_dataloader, desc=f\"Training epoch {self.epoch}\", \n",
    "                leave=False, mininterval=cfg.training.tqdm_interval_sec) as tepoch:\n",
    "            for batch_idx, batch in enumerate(tepoch):\n",
    "                # device transfer\n",
    "                batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "                if train_sampling_batch is None:\n",
    "                    train_sampling_batch = batch\n",
    "\n",
    "                # compute loss\n",
    "                raw_loss = self.model.compute_loss(batch)\n",
    "                loss = raw_loss / cfg.training.gradient_accumulate_every\n",
    "                loss.backward()\n",
    "\n",
    "                # step optimizer\n",
    "                if self.global_step % cfg.training.gradient_accumulate_every == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    lr_scheduler.step()\n",
    "                \n",
    "                # update ema\n",
    "                if cfg.training.use_ema:\n",
    "                    ema.step(self.model)\n",
    "\n",
    "                # logging\n",
    "                raw_loss_cpu = raw_loss.item()\n",
    "                tepoch.set_postfix(loss=raw_loss_cpu, refresh=False)\n",
    "                train_losses.append(raw_loss_cpu)\n",
    "                step_log = {\n",
    "                    'train_loss': raw_loss_cpu,\n",
    "                    'global_step': self.global_step,\n",
    "                    'epoch': self.epoch,\n",
    "                    'lr': lr_scheduler.get_last_lr()[0]\n",
    "                }\n",
    "\n",
    "                is_last_batch = (batch_idx == (len(train_dataloader)-1))\n",
    "                if not is_last_batch:\n",
    "                    # log of last step is combined with validation and rollout\n",
    "                     \n",
    "                    json_logger.log(step_log)\n",
    "                    self.global_step += 1\n",
    "\n",
    "                if (cfg.training.max_train_steps is not None) \\\n",
    "                    and batch_idx >= (cfg.training.max_train_steps-1):\n",
    "                    break\n",
    "\n",
    "        # at the end of each epoch\n",
    "        # replace train_loss with epoch average\n",
    "        train_loss = np.mean(train_losses)\n",
    "        step_log['train_loss'] = train_loss\n",
    "\n",
    "        # ========= eval for this epoch ==========\n",
    "        policy = self.model\n",
    "        if cfg.training.use_ema:\n",
    "            policy = self.ema_model\n",
    "        policy.eval()\n",
    "\n",
    "        # run rollout\n",
    "        if (self.epoch % cfg.training.rollout_every) == 0:\n",
    "            runner_log = env_runner.run(policy)\n",
    "            # log all\n",
    "            step_log.update(runner_log)\n",
    "\n",
    "        # run validation\n",
    "        if (self.epoch % cfg.training.val_every) == 0:\n",
    "            with torch.no_grad():\n",
    "                val_losses = list()\n",
    "                with tqdm.tqdm(val_dataloader, desc=f\"Validation epoch {self.epoch}\", \n",
    "                        leave=False, mininterval=cfg.training.tqdm_interval_sec) as tepoch:\n",
    "                    for batch_idx, batch in enumerate(tepoch):\n",
    "                        batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "                        loss = self.model.compute_loss(batch)\n",
    "                        val_losses.append(loss)\n",
    "                        if (cfg.training.max_val_steps is not None) \\\n",
    "                            and batch_idx >= (cfg.training.max_val_steps-1):\n",
    "                            break\n",
    "                if len(val_losses) > 0:\n",
    "                    val_loss = torch.mean(torch.tensor(val_losses)).item()\n",
    "                    # log epoch average validation loss\n",
    "                    step_log['val_loss'] = val_loss\n",
    "\n",
    "        # run diffusion sampling on a training batch\n",
    "        if (self.epoch % cfg.training.sample_every) == 0:\n",
    "            with torch.no_grad():\n",
    "                # sample trajectory from training set, and evaluate difference\n",
    "                batch = dict_apply(train_sampling_batch, lambda x: x.to(device, non_blocking=True))\n",
    "                obs_dict = batch['obs']\n",
    "                gt_action = batch['action']\n",
    "                \n",
    "                result = policy.predict_action(obs_dict)\n",
    "                pred_action = result['action_pred']\n",
    "                mse = torch.nn.functional.mse_loss(pred_action, gt_action)\n",
    "                step_log['train_action_mse_error'] = mse.item()\n",
    "                del batch\n",
    "                del obs_dict\n",
    "                del gt_action\n",
    "                del result\n",
    "                del pred_action\n",
    "                del mse\n",
    "        \n",
    "        # checkpoint\n",
    "        if (self.epoch % cfg.training.checkpoint_every) == 0:\n",
    "            # checkpointing\n",
    "            if cfg.checkpoint.save_last_ckpt:\n",
    "                self.save_checkpoint()\n",
    "            if cfg.checkpoint.save_last_snapshot:\n",
    "                self.save_snapshot()\n",
    "\n",
    "            # sanitize metric names\n",
    "            metric_dict = dict()\n",
    "            for key, value in step_log.items():\n",
    "                new_key = key.replace('/', '_')\n",
    "                metric_dict[new_key] = value\n",
    "            \n",
    "            # We can't copy the last checkpoint here\n",
    "            # since save_checkpoint uses threads.\n",
    "            # therefore at this point the file might have been empty!\n",
    "            topk_ckpt_path = topk_manager.get_ckpt_path(metric_dict)\n",
    "\n",
    "            if topk_ckpt_path is not None:\n",
    "                self.save_checkpoint(path=topk_ckpt_path)\n",
    "        # ========= eval end for this epoch ==========\n",
    "        policy.train()\n",
    "\n",
    "        # end of epoch\n",
    "        # log of last step is combined with validation and rollout\n",
    "         \n",
    "        json_logger.log(step_log)\n",
    "        self.global_step += 1\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
