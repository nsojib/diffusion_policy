{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carl_lab/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# use line-buffering for both stdout and stderr\n",
    "# sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1)\n",
    "# sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1)\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "import pathlib\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    " \n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "# from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.robomimic_lowdim_policy import RobomimicLowdimPolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "from diffusion_policy.env_runner.base_lowdim_runner import BaseLowdimRunner\n",
    "from diffusion_policy.common.checkpoint_util import TopKCheckpointManager\n",
    "from diffusion_policy.common.json_logger import JsonLogger\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "\n",
    "from diffusion_policy.policy.robomimic_lowdim_policy import RobomimicLowdimPolicy\n",
    "from diffusion_policy.policy.robomimic_image_policy import RobomimicImagePolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "\n",
    "# from diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace import TrainDiffusionUnetHybridWorkspace\n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.diffusion_unet_hybrid_image_policy import DiffusionUnetHybridImagePolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "from diffusion_policy.common.checkpoint_util import TopKCheckpointManager\n",
    "from diffusion_policy.common.json_logger import JsonLogger\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "from diffusion_policy.model.diffusion.ema_model import EMAModel\n",
    "from diffusion_policy.model.common.lr_scheduler import get_scheduler\n",
    "\n",
    "from diffusion_policy.dataset.robomimic_replay_image_dataset import RobomimicReplayImageDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Sampler \n",
    "\n",
    "import h5py\n",
    "\n",
    "# import mimicgen\n",
    "# import mimicgen.utils.file_utils as MG_FileUtils\n",
    "# import mimicgen.utils.robomimic_utils as RobomimicUtils\n",
    "# from mimicgen.utils.misc_utils import add_red_border_to_frame\n",
    "# from mimicgen.configs import MG_TaskSpec\n",
    "\n",
    "OmegaConf.register_new_resolver(\"eval\", eval, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='.' \n",
    "config_name = \"image_franka_image_240_320\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace.TrainDiffusionUnetHybridWorkspace', 'checkpoint': {'save_last_ckpt': True, 'save_last_snapshot': False, 'topk': {'format_str': 'epoch={epoch:04d}-test_mean_score={test_mean_score:.3f}.ckpt', 'k': 5, 'mode': 'max', 'monitor_key': 'test_mean_score'}}, 'dataloader': {'batch_size': 64, 'num_workers': 8, 'persistent_workers': False, 'pin_memory': True, 'shuffle': True}, 'dataset_obs_steps': 2, 'ema': {'_target_': 'diffusion_policy.model.diffusion.ema_model.EMAModel', 'inv_gamma': 1.0, 'max_value': 0.9999, 'min_value': 0.0, 'power': 0.75, 'update_after_step': 0}, 'exp_name': 'default', 'horizon': 16, 'keypoint_visible_rate': 1.0, 'logging': {'group': None, 'id': None, 'mode': 'online', 'name': '2022.12.29-22.31.41_train_diffusion_unet_hybrid_square_image', 'project': 'diffusion_policy_debug', 'resume': True, 'tags': ['train_diffusion_unet_hybrid', 'square_image', 'default']}, 'multi_run': {'run_dir': 'data/outputs/2022.12.29/22.31.41_train_diffusion_unet_hybrid_square_image', 'wandb_name_base': '2022.12.29-22.31.41_train_diffusion_unet_hybrid_square_image'}, 'n_action_steps': 8, 'n_latency_steps': 0, 'n_obs_steps': 2, 'name': 'train_diffusion_unet_hybrid', 'obs_as_global_cond': True, 'optimizer': {'_target_': 'torch.optim.AdamW', 'betas': [0.95, 0.999], 'eps': 1e-08, 'lr': 0.0001, 'weight_decay': 1e-06}, 'past_action_visible': False, 'policy': {'_target_': 'diffusion_policy.policy.diffusion_unet_hybrid_image_policy.DiffusionUnetHybridImagePolicy', 'cond_predict_scale': True, 'crop_shape': [180, 180], 'diffusion_step_embed_dim': 128, 'down_dims': [512, 1024, 2048], 'eval_fixed_crop': True, 'horizon': 16, 'kernel_size': 5, 'n_action_steps': 8, 'n_groups': 8, 'n_obs_steps': 2, 'noise_scheduler': {'_target_': 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler', 'beta_end': 0.02, 'beta_schedule': 'squaredcos_cap_v2', 'beta_start': 0.0001, 'clip_sample': True, 'num_train_timesteps': 100, 'prediction_type': 'epsilon', 'variance_type': 'fixed_small'}, 'num_inference_steps': 100, 'obs_as_global_cond': True, 'obs_encoder_group_norm': True, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}}, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'task': {'abs_action': True, 'dataset': {'_target_': 'diffusion_policy.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset', 'abs_action': True, 'dataset_path': '/home/carl_lab/ns/60_drawer_bellpepper_s2ie.hdf5', 'horizon': 16, 'n_obs_steps': 2, 'pad_after': 7, 'pad_before': 1, 'rotation_rep': 'rotation_6d', 'seed': 42, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'use_cache': False, 'val_ratio': 0.02}, 'dataset_path': '/home/carl_lab/ns/60_drawer_bellpepper_s2ie.hdf5', 'dataset_type': 'mh', 'env_runner': {'_target_': 'diffusion_policy.env_runner.robomimic_image_runner.RobomimicImageRunner', 'abs_action': True, 'crf': 22, 'dataset_path': '/home/carl_lab/ns/60_drawer_bellpepper_s2ie.hdf5', 'fps': 10, 'max_steps': 500, 'n_action_steps': 8, 'n_envs': 28, 'n_obs_steps': 2, 'n_test': 50, 'n_test_vis': 4, 'n_train': 6, 'n_train_vis': 2, 'past_action': False, 'render_obs_key': 'agentview_rgb', 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'test_start_seed': 100000, 'tqdm_interval_sec': 1.0, 'train_start_idx': 0}, 'name': 'square_image', 'shape_meta': {'action': {'shape': [10]}, 'obs': {'agentview_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'task_name': 'square'}, 'task_name': 'square_image', 'training': {'checkpoint_every': 50, 'debug': False, 'device': 'cuda:0', 'gradient_accumulate_every': 1, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'max_train_steps': None, 'max_val_steps': None, 'num_epochs': 1000, 'resume': True, 'rollout_every': 50, 'sample_every': 5, 'seed': 42, 'tqdm_interval_sec': 1.0, 'use_ema': True, 'val_every': 1}, 'val_dataloader': {'batch_size': 32, 'num_workers': 8, 'persistent_workers': False, 'pin_memory': True, 'shuffle': False}}\n",
      "resume:  True\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=config_path):\n",
    "    cfg_org = compose(\n",
    "        config_name=config_name,\n",
    "        overrides=[\n",
    "            \"hydra.run.dir=data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}\",\n",
    "            \"training.seed=42\",\n",
    "            \"training.device=cuda:0\"\n",
    "        ],\n",
    "    )\n",
    "    print(cfg_org)\n",
    "    \n",
    "OmegaConf.resolve(cfg_org)\n",
    "\n",
    "print('resume: ', cfg_org.training.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint_dir = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDiffusionUnetHybridWorkspace(BaseWorkspace):\n",
    "    include_keys = ['global_step', 'epoch']\n",
    "\n",
    "    def __init__(self, cfg: OmegaConf, output_dir=None):\n",
    "        super().__init__(cfg, output_dir=output_dir)\n",
    "\n",
    "        # set seed\n",
    "        seed = cfg.training.seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # configure model\n",
    "        self.model: DiffusionUnetHybridImagePolicy = hydra.utils.instantiate(cfg.policy)\n",
    "\n",
    "        self.ema_model: DiffusionUnetHybridImagePolicy = None\n",
    "        if cfg.training.use_ema:\n",
    "            self.ema_model = copy.deepcopy(self.model)\n",
    "\n",
    "        # configure training state\n",
    "        self.optimizer = hydra.utils.instantiate(\n",
    "            cfg.optimizer, params=self.model.parameters())\n",
    "\n",
    "        # configure training state\n",
    "        self.global_step = 0\n",
    "        self.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recreating workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['gripper_states', 'ee_states', 'joint_states']\n",
      "using obs modality: rgb with keys: ['eye_in_hand_rgb', 'agentview_rgb']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carl_lab/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/carl_lab/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion params: 2.564722e+08\n",
      "Vision params: 2.239418e+07\n",
      "output dir:  /home/carl_lab/diffusion_policy/data/outputs/custom2025_09_15_01_18_12_s2ie\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "output_dir = f\"/home/carl_lab/diffusion_policy/data/outputs/custom{timestamp}_s2ie\"\n",
    "os.mkdir(output_dir)\n",
    "workspace = TrainDiffusionUnetHybridWorkspace(cfg_org, output_dir=output_dir)\n",
    "\n",
    "self = workspace\n",
    "print('output dir: ', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = copy.deepcopy(self.cfg)\n",
    "\n",
    "# resume training\n",
    "# if cfg.training.resume:\n",
    "#     lastest_ckpt_path = self.get_checkpoint_path()\n",
    "#     if lastest_ckpt_path.is_file():\n",
    "#         print(f\"Resuming from checkpoint {lastest_ckpt_path}\")\n",
    "#         self.load_checkpoint(path=lastest_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "dataset_path:  /home/carl_lab/ns/60_drawer_bellpepper_s2ie.hdf5\n",
      "dataset filter key:  None\n",
      "----------------------------\n",
      "------------------------------ self.n_demo=60------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading lowdim data: 100%|██████████| 5/5 [00:00<00:00, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "adding key=ee_states with shape (24083, 16)\n",
      "------------------------\n",
      "------------------------\n",
      "adding key=joint_states with shape (24083, 7)\n",
      "------------------------\n",
      "------------------------\n",
      "adding key=gripper_states with shape (24083, 1)\n",
      "------------------------\n",
      "------------------------\n",
      "adding key=action with shape (24083, 10)\n",
      "------------------------\n",
      "this_data.shape= (24083,) 24083 [10]\n",
      "------------------------\n",
      "adding key=marks with shape (24083,)\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading image data: 100%|██████████| 48166/48166 [01:08<00:00, 698.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22990"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config = OmegaConf.to_container(cfg.task.dataset, resolve=True )\n",
    "new_config['n_demo'] = 60\n",
    "del new_config['_target_']\n",
    "\n",
    "dataset = RobomimicReplayImageDataset(**new_config)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dataloader = {key:value for key,value in cfg.dataloader.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, **cfg_dataloader)\n",
    "normalizer = dataset.get_normalizer()\n",
    "\n",
    "# configure validation dataset\n",
    "val_dataset = dataset.get_validation_dataset()\n",
    "val_dataloader = DataLoader(val_dataset, **cfg.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obs', 'action'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch =  next(iter(train_dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 3, 240, 320])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['obs']['agentview_rgb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model.set_normalizer(normalizer)\n",
    "if cfg.training.use_ema:\n",
    "    self.ema_model.set_normalizer(normalizer)\n",
    "\n",
    "# configure lr scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    cfg.training.lr_scheduler,\n",
    "    optimizer=self.optimizer,\n",
    "    num_warmup_steps=cfg.training.lr_warmup_steps,\n",
    "    num_training_steps=(\n",
    "        len(train_dataloader) * cfg.training.num_epochs) \\\n",
    "            // cfg.training.gradient_accumulate_every,\n",
    "    # pytorch assumes stepping LRScheduler every epoch\n",
    "    # however huggingface diffusers steps it every batch\n",
    "    last_epoch=self.global_step-1\n",
    ")\n",
    "\n",
    "# configure ema\n",
    "ema: EMAModel = None\n",
    "if cfg.training.use_ema:\n",
    "    ema = hydra.utils.instantiate(\n",
    "        cfg.ema,\n",
    "        model=self.ema_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.95, 0.999]\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    initial_lr: 0.0001\n",
       "    lr: 0.0\n",
       "    maximize: False\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_manager = TopKCheckpointManager(\n",
    "    save_dir=os.path.join(self.output_dir, 'checkpoints'),\n",
    "    **cfg.checkpoint.topk\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device(cfg.training.device)\n",
    "self.model.to(device)\n",
    "if self.ema_model is not None:\n",
    "    self.ema_model.to(device)\n",
    "optimizer_to(self.optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dir:  /home/carl_lab/diffusion_policy/data/outputs/custom2025_09_15_01_18_12_s2ie\n"
     ]
    }
   ],
   "source": [
    "print('output dir: ', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 18:  12%|█▏        | 42/360 [00:14<01:34,  3.37it/s, loss=0.0183] "
     ]
    }
   ],
   "source": [
    "train_sampling_batch = None\n",
    "log_path = os.path.join(self.output_dir, 'logs.json.txt')\n",
    "with JsonLogger(log_path) as json_logger:\n",
    "    for local_epoch_idx in range(cfg.training.num_epochs):\n",
    "        step_log = dict()\n",
    "        # ========= train for this epoch ==========\n",
    "        train_losses = list()\n",
    "        with tqdm.tqdm(train_dataloader, desc=f\"Training epoch {self.epoch}\", \n",
    "                leave=False, mininterval=cfg.training.tqdm_interval_sec) as tepoch:\n",
    "            for batch_idx, batch in enumerate(tepoch):\n",
    "                # device transfer\n",
    "                batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "                if train_sampling_batch is None:\n",
    "                    train_sampling_batch = batch\n",
    "\n",
    "                # compute loss\n",
    "                raw_loss = self.model.compute_loss(batch)\n",
    "                loss = raw_loss / cfg.training.gradient_accumulate_every\n",
    "                loss.backward()\n",
    "\n",
    "                # step optimizer\n",
    "                if self.global_step % cfg.training.gradient_accumulate_every == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    lr_scheduler.step()\n",
    "                \n",
    "                # update ema\n",
    "                if cfg.training.use_ema:\n",
    "                    ema.step(self.model)\n",
    "\n",
    "                # logging\n",
    "                raw_loss_cpu = raw_loss.item()\n",
    "                tepoch.set_postfix(loss=raw_loss_cpu, refresh=False)\n",
    "                train_losses.append(raw_loss_cpu)\n",
    "                step_log = {\n",
    "                    'train_loss': raw_loss_cpu,\n",
    "                    'global_step': self.global_step,\n",
    "                    'epoch': self.epoch,\n",
    "                    'lr': lr_scheduler.get_last_lr()[0]\n",
    "                }\n",
    "\n",
    "                is_last_batch = (batch_idx == (len(train_dataloader)-1))\n",
    "                if not is_last_batch:\n",
    "                    # log of last step is combined with validation and rollout\n",
    "                     \n",
    "                    json_logger.log(step_log)\n",
    "                    self.global_step += 1\n",
    "\n",
    "                if (cfg.training.max_train_steps is not None) \\\n",
    "                    and batch_idx >= (cfg.training.max_train_steps-1):\n",
    "                    break\n",
    "\n",
    "        # at the end of each epoch\n",
    "        # replace train_loss with epoch average\n",
    "        train_loss = np.mean(train_losses)\n",
    "        step_log['train_loss'] = train_loss\n",
    "\n",
    "        # ========= eval for this epoch ==========\n",
    "        policy = self.model\n",
    "        if cfg.training.use_ema:\n",
    "            policy = self.ema_model\n",
    "        policy.eval()\n",
    "\n",
    " \n",
    "        # run validation\n",
    "        if (self.epoch % cfg.training.val_every) == 0:\n",
    "            with torch.no_grad():\n",
    "                val_losses = list()\n",
    "                with tqdm.tqdm(val_dataloader, desc=f\"Validation epoch {self.epoch}\", \n",
    "                        leave=False, mininterval=cfg.training.tqdm_interval_sec) as tepoch:\n",
    "                    for batch_idx, batch in enumerate(tepoch):\n",
    "                        batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "                        loss = self.model.compute_loss(batch)\n",
    "                        val_losses.append(loss)\n",
    "                        if (cfg.training.max_val_steps is not None) \\\n",
    "                            and batch_idx >= (cfg.training.max_val_steps-1):\n",
    "                            break\n",
    "                if len(val_losses) > 0:\n",
    "                    val_loss = torch.mean(torch.tensor(val_losses)).item()\n",
    "                    # log epoch average validation loss\n",
    "                    step_log['val_loss'] = val_loss\n",
    "\n",
    "        # run diffusion sampling on a training batch\n",
    "        if (self.epoch % cfg.training.sample_every) == 0:\n",
    "            with torch.no_grad():\n",
    "                # sample trajectory from training set, and evaluate difference\n",
    "                batch = dict_apply(train_sampling_batch, lambda x: x.to(device, non_blocking=True))\n",
    "                obs_dict = batch['obs']\n",
    "                gt_action = batch['action']\n",
    "                \n",
    "                result = policy.predict_action(obs_dict)\n",
    "                pred_action = result['action_pred']\n",
    "                mse = torch.nn.functional.mse_loss(pred_action, gt_action)\n",
    "                step_log['train_action_mse_error'] = mse.item()\n",
    "                del batch\n",
    "                del obs_dict\n",
    "                del gt_action\n",
    "                del result\n",
    "                del pred_action\n",
    "                del mse\n",
    "        \n",
    "        # checkpoint\n",
    "        if self.epoch > 300 and (self.epoch % 200) == 0:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            # self.save_checkpoint(tag=f'epoch_{self.epoch}') \n",
    "            checkpoint_name = f'epoch_{self.epoch}_{timestamp}'\n",
    "            path_ = self.save_checkpoint(tag=checkpoint_name)\n",
    "            print(path_)\n",
    "\n",
    "            \n",
    "        # ========= eval end for this epoch ==========\n",
    "        policy.train()\n",
    "\n",
    "        # end of epoch\n",
    "        # log of last step is combined with validation and rollout\n",
    "         \n",
    "        json_logger.log(step_log)\n",
    "        self.global_step += 1\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.save_checkpoint(tag=f\"after_train_{self.epoch}_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
