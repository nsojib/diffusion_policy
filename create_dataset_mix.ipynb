{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/home/carl_lab/data_franka/mixed_o40z5tal3l5taz5.hdf5\"\n",
    "\n",
    "dataset_path_ola40 = \"/home/carl_lab/data_franka/drawer_ola/demo_sub40.hdf5\"\n",
    "f_org_ola = h5py.File(dataset_path_ola40, \"r\")\n",
    "\n",
    "## actually tazul \n",
    "dataset_path_talha = \"/home/carl_lab/data_franka/drawer_lay/drawer_tazul_g12b3.hdf5\"\n",
    "f_org_talha = h5py.File(dataset_path_talha, \"r\")\n",
    "\n",
    "dataset_path_zahid = \"/home/carl_lab/data_franka/drawer_lay/drawer_zahid_g6b5.hdf5\"\n",
    "f_org_zahid = h5py.File(dataset_path_zahid, \"r\")\n",
    "\n",
    "dataset_path_lynn =  \"/home/carl_lab/data_franka/sat_lynn_tazul/imgsd_demo_lynn/demo.hdf5\"\n",
    "f_org_lynn = h5py.File(dataset_path_lynn, \"r\")\n",
    "\n",
    "dataset_path_lynn2 =  \"/home/carl_lab/data_franka/sat_lynn_tazul/imgsd_demo_lynn2/demo.hdf5\"\n",
    "f_org_lynn2 = h5py.File(dataset_path_lynn2, \"r\")\n",
    "\n",
    "dataset_path_tazul = \"/home/carl_lab/data_franka/sat_lynn_tazul/imgsd_demo_tazul/demo.hdf5\"\n",
    "f_org_tazul = h5py.File(dataset_path_tazul, \"r\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/home/carl_lab/data_franka/bellpepper_good40.hdf5\"\n",
    "\n",
    "dataset_path_good40 = \"/home/carl_lab/data_franka/combined_oma_good_180.hdf5\"\n",
    "f_org_good40 = h5py.File(dataset_path_good40, \"r\")\n",
    "\n",
    "\n",
    "dataset_path_bad = \"/home/carl_lab/data_franka/combined_oma_bad_107.hdf5\"\n",
    "f_org_bad = h5py.File(dataset_path_bad, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['demo_0', 'demo_1', 'demo_10', 'demo_100', 'demo_101', 'demo_102', 'demo_103', 'demo_104', 'demo_105', 'demo_106', 'demo_11', 'demo_12', 'demo_13', 'demo_14', 'demo_15', 'demo_16', 'demo_17', 'demo_18', 'demo_19', 'demo_2', 'demo_20', 'demo_21', 'demo_22', 'demo_23', 'demo_24', 'demo_25', 'demo_26', 'demo_27', 'demo_28', 'demo_29', 'demo_3', 'demo_30', 'demo_31', 'demo_32', 'demo_33', 'demo_34', 'demo_35', 'demo_36', 'demo_37', 'demo_38', 'demo_39', 'demo_4', 'demo_40', 'demo_41', 'demo_42', 'demo_43', 'demo_44', 'demo_45', 'demo_46', 'demo_47', 'demo_48', 'demo_49', 'demo_5', 'demo_50', 'demo_51', 'demo_52', 'demo_53', 'demo_54', 'demo_55', 'demo_56', 'demo_57', 'demo_58', 'demo_59', 'demo_6', 'demo_60', 'demo_61', 'demo_62', 'demo_63', 'demo_64', 'demo_65', 'demo_66', 'demo_67', 'demo_68', 'demo_69', 'demo_7', 'demo_70', 'demo_71', 'demo_72', 'demo_73', 'demo_74', 'demo_75', 'demo_76', 'demo_77', 'demo_78', 'demo_79', 'demo_8', 'demo_80', 'demo_81', 'demo_82', 'demo_83', 'demo_84', 'demo_85', 'demo_86', 'demo_87', 'demo_88', 'demo_89', 'demo_9', 'demo_90', 'demo_91', 'demo_92', 'demo_93', 'demo_94', 'demo_95', 'demo_96', 'demo_97', 'demo_98', 'demo_99']>\n",
      "<KeysViewHDF5 ['akash_100', 'marzan_73', 'ola_114']>\n"
     ]
    }
   ],
   "source": [
    "print(f_org_bad['data'].keys())\n",
    "print(f_org_bad['mask'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data', 'mask']>\n",
      "<KeysViewHDF5 ['demo_0', 'demo_1', 'demo_10', 'demo_11', 'demo_12', 'demo_13', 'demo_14', 'demo_15', 'demo_16', 'demo_17', 'demo_18', 'demo_19', 'demo_2', 'demo_20', 'demo_21', 'demo_22', 'demo_23', 'demo_24', 'demo_25', 'demo_26', 'demo_27', 'demo_28', 'demo_29', 'demo_3', 'demo_30', 'demo_31', 'demo_32', 'demo_33', 'demo_34', 'demo_35', 'demo_36', 'demo_37', 'demo_38', 'demo_39', 'demo_4', 'demo_5', 'demo_6', 'demo_7', 'demo_8', 'demo_9']>\n",
      "<KeysViewHDF5 []>\n"
     ]
    }
   ],
   "source": [
    "print(f_org_ola.keys())\n",
    "print(f_org_ola['data'].keys())\n",
    "print(f_org_ola['mask'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data', 'mask']>\n",
      "<KeysViewHDF5 ['bad', 'good']>\n"
     ]
    }
   ],
   "source": [
    "print(f_org_talha.keys())\n",
    "print(f_org_talha['mask'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_group(src_group, dest_group):\n",
    "    # Copy attributes\n",
    "    for attr_name, attr_value in src_group.attrs.items():\n",
    "        dest_group.attrs[attr_name] = attr_value\n",
    "\n",
    "    for key, item in src_group.items():\n",
    "        if isinstance(item, h5py.Group):\n",
    "            # Create a new group in the destination and recursively copy contents\n",
    "            new_group = dest_group.create_group(key)\n",
    "            copy_group(item, new_group)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            # Copy datasets\n",
    "            dataset = dest_group.create_dataset(key, data=item[...])\n",
    "            # Copy attributes for the dataset\n",
    "            for attr_name, attr_value in item.attrs.items():\n",
    "                dataset.attrs[attr_name] = attr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_org_good40, old, new demo_0 demo_0\n",
      "f_org_good40, old, new demo_1 demo_1\n",
      "f_org_good40, old, new demo_10 demo_2\n",
      "f_org_good40, old, new demo_100 demo_3\n",
      "f_org_good40, old, new demo_101 demo_4\n",
      "f_org_good40, old, new demo_102 demo_5\n",
      "f_org_good40, old, new demo_103 demo_6\n",
      "f_org_good40, old, new demo_104 demo_7\n",
      "f_org_good40, old, new demo_105 demo_8\n",
      "f_org_good40, old, new demo_106 demo_9\n",
      "f_org_good40, old, new demo_107 demo_10\n",
      "f_org_good40, old, new demo_108 demo_11\n",
      "f_org_good40, old, new demo_109 demo_12\n",
      "f_org_good40, old, new demo_11 demo_13\n",
      "f_org_good40, old, new demo_110 demo_14\n",
      "f_org_good40, old, new demo_111 demo_15\n",
      "f_org_good40, old, new demo_112 demo_16\n",
      "f_org_good40, old, new demo_113 demo_17\n",
      "f_org_good40, old, new demo_114 demo_18\n",
      "f_org_good40, old, new demo_115 demo_19\n",
      "f_org_good40, old, new demo_116 demo_20\n",
      "f_org_good40, old, new demo_117 demo_21\n",
      "f_org_good40, old, new demo_118 demo_22\n",
      "f_org_good40, old, new demo_119 demo_23\n",
      "f_org_good40, old, new demo_12 demo_24\n",
      "f_org_good40, old, new demo_120 demo_25\n",
      "f_org_good40, old, new demo_121 demo_26\n",
      "f_org_good40, old, new demo_122 demo_27\n",
      "f_org_good40, old, new demo_123 demo_28\n",
      "f_org_good40, old, new demo_124 demo_29\n",
      "f_org_good40, old, new demo_125 demo_30\n",
      "f_org_good40, old, new demo_126 demo_31\n",
      "f_org_good40, old, new demo_127 demo_32\n",
      "f_org_good40, old, new demo_128 demo_33\n",
      "f_org_good40, old, new demo_129 demo_34\n",
      "f_org_good40, old, new demo_13 demo_35\n",
      "f_org_good40, old, new demo_130 demo_36\n",
      "f_org_good40, old, new demo_131 demo_37\n",
      "f_org_good40, old, new demo_132 demo_38\n",
      "f_org_good40, old, new demo_133 demo_39\n",
      "demo_counter:  40\n",
      "new_target:  50\n",
      "bad_demos_akash, old, new:  demo_100 demo_40\n",
      "bad_demos_akash, old, new:  demo_101 demo_41\n",
      "bad_demos_akash, old, new:  demo_102 demo_42\n",
      "bad_demos_akash, old, new:  demo_103 demo_43\n",
      "bad_demos_akash, old, new:  demo_104 demo_44\n",
      "bad_demos_akash, old, new:  demo_105 demo_45\n",
      "bad_demos_akash, old, new:  demo_106 demo_46\n",
      "bad_demos_akash, old, new:  demo_42 demo_47\n",
      "bad_demos_akash, old, new:  demo_43 demo_48\n",
      "bad_demos_akash, old, new:  demo_44 demo_49\n",
      "demo_counter:  50\n",
      "new_target:  55\n",
      "bad_demos_marzan, old, new:  demo_20 demo_50\n",
      "bad_demos_marzan, old, new:  demo_21 demo_51\n",
      "bad_demos_marzan, old, new:  demo_22 demo_52\n",
      "bad_demos_marzan, old, new:  demo_23 demo_53\n",
      "bad_demos_marzan, old, new:  demo_24 demo_54\n",
      "demo_counter:  55\n",
      "new_target:  60\n",
      "bad_demos_ola, old, new:  demo_0 demo_55\n",
      "bad_demos_ola, old, new:  demo_1 demo_56\n",
      "bad_demos_ola, old, new:  demo_10 demo_57\n",
      "bad_demos_ola, old, new:  demo_11 demo_58\n",
      "bad_demos_ola, old, new:  demo_12 demo_59\n"
     ]
    }
   ],
   "source": [
    "bad_demos_akash = [name.decode(\"utf-8\") for name in f_org_bad['mask']['akash_100']]\n",
    "bad_demos_marzan = [name.decode(\"utf-8\") for name in f_org_bad['mask']['marzan_73']]\n",
    "bad_demos_ola = [name.decode(\"utf-8\") for name in f_org_bad['mask']['ola_114']]\n",
    "\n",
    "with h5py.File(output_path, \"w\") as f_new:\n",
    "    # Create the data group in the new dataset\n",
    "    data_group = f_new.create_group(\"data\")\n",
    "    demo_counter = 0  # Start numbering from 0\n",
    "    \n",
    "    target_good = 40\n",
    "    target_ola = 5\n",
    "    target_akash = 10\n",
    "    target_marzan = 5\n",
    "    \n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_good40['data']:\n",
    "        if demo_counter >= target_good:\n",
    "            break\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"f_org_good40, old, new\", demo_name, new_demo_name)\n",
    "        demo=f_org_good40['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "        \n",
    "    print(\"demo_counter: \", demo_counter)\n",
    "    new_target = target_good + target_akash\n",
    "    print(\"new_target: \",new_target)\n",
    "    \n",
    "    for demo_name in bad_demos_akash:\n",
    "        if demo_counter  >= (new_target):\n",
    "            break\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"bad_demos_akash, old, new: \", demo_name, new_demo_name)\n",
    "        demo=f_org_bad['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1     \n",
    "    \n",
    "    print(\"demo_counter: \", demo_counter)\n",
    "    new_target += target_marzan\n",
    "    print(\"new_target: \",new_target)\n",
    "    \n",
    "    for demo_name in bad_demos_marzan:\n",
    "        if demo_counter  >= (new_target):\n",
    "            break\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"bad_demos_marzan, old, new: \",demo_name, new_demo_name)\n",
    "        demo=f_org_bad['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1     \n",
    "    \n",
    "    print(\"demo_counter: \", demo_counter)\n",
    "    new_target += target_ola\n",
    "    print(\"new_target: \",new_target)\n",
    "    \n",
    "    for demo_name in bad_demos_ola:\n",
    "        if demo_counter  >= (new_target):\n",
    "            break\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"bad_demos_ola, old, new: \",demo_name, new_demo_name)\n",
    "        demo=f_org_bad['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1     \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_org_good40, old, new demo_0 demo_0\n",
      "f_org_good40, old, new demo_1 demo_1\n",
      "f_org_good40, old, new demo_10 demo_2\n",
      "f_org_good40, old, new demo_100 demo_3\n",
      "f_org_good40, old, new demo_101 demo_4\n",
      "f_org_good40, old, new demo_102 demo_5\n",
      "f_org_good40, old, new demo_103 demo_6\n",
      "f_org_good40, old, new demo_104 demo_7\n",
      "f_org_good40, old, new demo_105 demo_8\n",
      "f_org_good40, old, new demo_106 demo_9\n",
      "f_org_good40, old, new demo_107 demo_10\n",
      "f_org_good40, old, new demo_108 demo_11\n",
      "f_org_good40, old, new demo_109 demo_12\n",
      "f_org_good40, old, new demo_11 demo_13\n",
      "f_org_good40, old, new demo_110 demo_14\n",
      "f_org_good40, old, new demo_111 demo_15\n",
      "f_org_good40, old, new demo_112 demo_16\n",
      "f_org_good40, old, new demo_113 demo_17\n",
      "f_org_good40, old, new demo_114 demo_18\n",
      "f_org_good40, old, new demo_115 demo_19\n",
      "f_org_good40, old, new demo_116 demo_20\n",
      "f_org_good40, old, new demo_117 demo_21\n",
      "f_org_good40, old, new demo_118 demo_22\n",
      "f_org_good40, old, new demo_119 demo_23\n",
      "f_org_good40, old, new demo_12 demo_24\n",
      "f_org_good40, old, new demo_120 demo_25\n",
      "f_org_good40, old, new demo_121 demo_26\n",
      "f_org_good40, old, new demo_122 demo_27\n",
      "f_org_good40, old, new demo_123 demo_28\n",
      "f_org_good40, old, new demo_124 demo_29\n",
      "f_org_good40, old, new demo_125 demo_30\n",
      "f_org_good40, old, new demo_126 demo_31\n",
      "f_org_good40, old, new demo_127 demo_32\n",
      "f_org_good40, old, new demo_128 demo_33\n",
      "f_org_good40, old, new demo_129 demo_34\n",
      "f_org_good40, old, new demo_13 demo_35\n",
      "f_org_good40, old, new demo_130 demo_36\n",
      "f_org_good40, old, new demo_131 demo_37\n",
      "f_org_good40, old, new demo_132 demo_38\n",
      "f_org_good40, old, new demo_133 demo_39\n",
      "demo_counter:  40\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_akash' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     demo_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemo_counter: \u001b[39m\u001b[38;5;124m\"\u001b[39m, demo_counter)\n\u001b[0;32m---> 19\u001b[0m new_target \u001b[38;5;241m=\u001b[39m target_good \u001b[38;5;241m+\u001b[39m \u001b[43mtarget_akash\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_target: \u001b[39m\u001b[38;5;124m\"\u001b[39m,new_target)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_akash' is not defined"
     ]
    }
   ],
   "source": [
    "with h5py.File(output_path, \"w\") as f_new:\n",
    "    # Create the data group in the new dataset\n",
    "    data_group = f_new.create_group(\"data\")\n",
    "    demo_counter = 0  # Start numbering from 0\n",
    "    \n",
    "    target_good = 40\n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_good40['data']:\n",
    "        if demo_counter >= target_good:\n",
    "            break\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"f_org_good40, old, new\", demo_name, new_demo_name)\n",
    "        demo=f_org_good40['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ola, old, new demo_0 demo_0\n",
      "ola, old, new demo_1 demo_1\n",
      "ola, old, new demo_10 demo_2\n",
      "ola, old, new demo_11 demo_3\n",
      "ola, old, new demo_12 demo_4\n",
      "ola, old, new demo_13 demo_5\n",
      "ola, old, new demo_14 demo_6\n",
      "ola, old, new demo_15 demo_7\n",
      "ola, old, new demo_16 demo_8\n",
      "ola, old, new demo_17 demo_9\n",
      "ola, old, new demo_18 demo_10\n",
      "ola, old, new demo_19 demo_11\n",
      "ola, old, new demo_2 demo_12\n",
      "ola, old, new demo_20 demo_13\n",
      "ola, old, new demo_21 demo_14\n",
      "ola, old, new demo_22 demo_15\n",
      "ola, old, new demo_23 demo_16\n",
      "ola, old, new demo_24 demo_17\n",
      "ola, old, new demo_25 demo_18\n",
      "ola, old, new demo_26 demo_19\n",
      "ola, old, new demo_27 demo_20\n",
      "ola, old, new demo_28 demo_21\n",
      "ola, old, new demo_29 demo_22\n",
      "ola, old, new demo_3 demo_23\n",
      "ola, old, new demo_30 demo_24\n",
      "ola, old, new demo_31 demo_25\n",
      "ola, old, new demo_32 demo_26\n",
      "ola, old, new demo_33 demo_27\n",
      "ola, old, new demo_34 demo_28\n",
      "ola, old, new demo_35 demo_29\n",
      "ola, old, new demo_36 demo_30\n",
      "ola, old, new demo_37 demo_31\n",
      "ola, old, new demo_38 demo_32\n",
      "ola, old, new demo_39 demo_33\n",
      "ola, old, new demo_4 demo_34\n",
      "ola, old, new demo_5 demo_35\n",
      "ola, old, new demo_6 demo_36\n",
      "ola, old, new demo_7 demo_37\n",
      "ola, old, new demo_8 demo_38\n",
      "ola, old, new demo_9 demo_39\n",
      "talha, old, new:  demo_4 demo_40\n",
      "talha, old, new:  demo_6 demo_41\n",
      "talha, old, new:  demo_8 demo_42\n",
      "zahid, old, new:  demo_0 demo_43\n",
      "zahid, old, new:  demo_3 demo_44\n",
      "zahid, old, new:  demo_6 demo_45\n",
      "zahid, old, new:  demo_8 demo_46\n",
      "zahid, old, new:  demo_9 demo_47\n",
      "lynn, old, new:  demo_12 demo_48\n",
      "lynn, old, new:  demo_4 demo_49\n",
      "lynn, old, new:  demo_7 demo_50\n",
      "lynn, old, new:  demo_9 demo_51\n",
      "lynn2, old, new:  demo_9 demo_52\n",
      "tazul, old , new:  demo_0 demo_53\n",
      "tazul, old , new:  demo_1 demo_54\n",
      "tazul, old , new:  demo_16 demo_55\n",
      "tazul, old , new:  demo_4 demo_56\n",
      "tazul, old , new:  demo_5 demo_57\n"
     ]
    }
   ],
   "source": [
    "bad_demos_talha = [name.decode(\"utf-8\") for name in f_org_talha['mask']['bad']]\n",
    "bad_demos_zahid = [name.decode(\"utf-8\") for name in f_org_zahid['mask']['bad']]\n",
    "bad_demos_lynn = [\"demo_4\",\"demo_12\",\"demo_7\",\"demo_9\"]\n",
    "bad_demos_lynn2 = [\"demo_9\"]\n",
    "bad_demos_tazul = [\"demo_0\",\"demo_1\",\"demo_4\",\"demo_5\",\"demo_16\"]\n",
    "\n",
    "with h5py.File(output_path, \"w\") as f_new:\n",
    "    # Create the data group in the new dataset\n",
    "    data_group = f_new.create_group(\"data\")\n",
    "    demo_counter = 0  # Start numbering from 0\n",
    "    \n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_ola['data']:\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"ola, old, new\",demo_name, new_demo_name)\n",
    "        demo=f_org_ola['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "    \n",
    "    # Copy only the bad demos from Talha\n",
    "    for demo_name_talha in f_org_talha['data']:\n",
    "        if demo_name_talha in bad_demos_talha:\n",
    "            new_demo_name = f\"demo_{demo_counter}\"  # Continue numbering from where Ola left off\n",
    "            print(\"talha, old, new: \",demo_name_talha, new_demo_name)\n",
    "            demo=f_org_talha['data'][demo_name_talha]  \n",
    "            new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "            copy_group(demo, new_demo) \n",
    "            demo_counter += 1\n",
    "            \n",
    "    # Copy only the bad demos from zahid\n",
    "    for demo_name_zahid in f_org_zahid['data']:\n",
    "        if demo_name_zahid in bad_demos_zahid:\n",
    "            new_demo_name = f\"demo_{demo_counter}\"  # Continue numbering from where Ola left off\n",
    "            print(\"zahid, old, new: \",demo_name_zahid, new_demo_name)\n",
    "            demo=f_org_zahid['data'][demo_name_zahid]  \n",
    "            new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "            copy_group(demo, new_demo) \n",
    "            demo_counter += 1\n",
    "            \n",
    "    # Copy only the bad demos from lynn\n",
    "    for demo_name_lynn in f_org_lynn['data']:\n",
    "        if demo_name_lynn in bad_demos_lynn:\n",
    "            new_demo_name = f\"demo_{demo_counter}\" \n",
    "            print(\"lynn, old, new: \",demo_name_lynn, new_demo_name)\n",
    "            demo=f_org_lynn['data'][demo_name_lynn]  \n",
    "            new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "            copy_group(demo, new_demo)\n",
    "            demo_counter += 1\n",
    "            \n",
    "    # # Copy only the bad demos from lynn2\n",
    "    for demo_name_lynn2 in f_org_lynn2['data']:\n",
    "        if demo_name_lynn2 in bad_demos_lynn2:\n",
    "            new_demo_name = f\"demo_{demo_counter}\" \n",
    "            print(\"lynn2, old, new: \",demo_name_lynn2, new_demo_name)\n",
    "            demo=f_org_lynn2['data'][demo_name_lynn2]  \n",
    "            new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "            copy_group(demo, new_demo)\n",
    "            demo_counter += 1\n",
    "            \n",
    "    # # Copy only the bad demos from tazul\n",
    "    for demo_name_tazul in f_org_tazul['data']:\n",
    "        if demo_name_tazul in bad_demos_tazul:\n",
    "            new_demo_name = f\"demo_{demo_counter}\" \n",
    "            print(\"tazul, old , new: \", demo_name_tazul, new_demo_name)\n",
    "            demo=f_org_tazul['data'][demo_name_tazul]  \n",
    "            new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "            copy_group(demo, new_demo)\n",
    "            demo_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demos:  60\n",
      "Max length:  497\n",
      "Min length:  115\n",
      "Mean length:  264.26666666666665\n",
      "Median length:  262.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path_base = \"/home/carl_lab/data_franka/mixed_bellpepper_good40bad5ola5marzan10akash.hdf5\"\n",
    "\n",
    "f_base = h5py.File(dataset_path_base, \"r\")\n",
    "demos = list(f_base[\"data\"].keys())\n",
    "\n",
    "lengths=[]\n",
    "demos_minmax={}\n",
    "for demo_name in demos:\n",
    "    demo=f_base['data'][demo_name]\n",
    "    num_samples=demo.attrs['num_samples']\n",
    "    lengths.append(num_samples)\n",
    "\n",
    "    action=f_base['data'][demo_name]['actions']\n",
    "    action=np.array(action) \n",
    "    demos_minmax[demo_name] = (np.min(action, axis=0), np.max(action, axis=0))\n",
    "\n",
    "\n",
    "lengths=np.array(lengths)\n",
    "\n",
    "print('Number of demos: ', len(demos))\n",
    "print('Max length: ', np.max(lengths))\n",
    "print('Min length: ', np.min(lengths))\n",
    "print('Mean length: ', np.mean(lengths))\n",
    "print('Median length: ', np.median(lengths))\n",
    "print('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_0\n",
      "demo_12\n",
      "demo_6\n",
      "demo_8\n"
     ]
    }
   ],
   "source": [
    "bad_demos_talha = [name.decode(\"utf-8\") for name in f_org_talha['mask']['bad']]\n",
    "bad_demos_zahid = [name.decode(\"utf-8\") for name in f_org_zahid['mask']['bad']]\n",
    "bad_demos_lynn = [\"demo_0\",\"demo_6\",\"demo_8\",\"demo_12\"]\n",
    "bad_demos_lynn2 = [\"demo_9\"]\n",
    "bad_demos_tazul = [\"demo_0\",\"demo_1\",\"demo_4\",\"demo_5\",\"demo_16\"]\n",
    "\n",
    "\n",
    "# Copy only the bad demos from lynn\n",
    "for demo_name_lynn in f_org_lynn['data']:\n",
    "    if demo_name_lynn in bad_demos_lynn:\n",
    "        print(demo_name_lynn)\n",
    "        \n",
    "        demo_counter += 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/home/carl_lab/data_franka/40_drawer_bellpepper.hdf5\"\n",
    "\n",
    "dataset_path_ola40_1 = \"/home/carl_lab/data_franka/ola20good2imgsd_demo/demo.hdf5\"\n",
    "f_org_ola1 = h5py.File(dataset_path_ola40_1, \"r\")\n",
    "\n",
    "dataset_path_ola40_2 = \"/home/carl_lab/data_franka/ola_20good_imgsd_demo/demo.hdf5\"\n",
    "f_org_ola2 = h5py.File(dataset_path_ola40_2, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_org_ola1, old, new demo_0 demo_0\n",
      "f_org_ola1, old, new demo_1 demo_1\n",
      "f_org_ola1, old, new demo_10 demo_2\n",
      "f_org_ola1, old, new demo_11 demo_3\n",
      "f_org_ola1, old, new demo_12 demo_4\n",
      "f_org_ola1, old, new demo_13 demo_5\n",
      "f_org_ola1, old, new demo_14 demo_6\n",
      "f_org_ola1, old, new demo_15 demo_7\n",
      "f_org_ola1, old, new demo_16 demo_8\n",
      "f_org_ola1, old, new demo_17 demo_9\n",
      "f_org_ola1, old, new demo_18 demo_10\n",
      "f_org_ola1, old, new demo_19 demo_11\n",
      "f_org_ola1, old, new demo_2 demo_12\n",
      "f_org_ola1, old, new demo_3 demo_13\n",
      "f_org_ola1, old, new demo_4 demo_14\n",
      "f_org_ola1, old, new demo_5 demo_15\n",
      "f_org_ola1, old, new demo_6 demo_16\n",
      "f_org_ola1, old, new demo_7 demo_17\n",
      "f_org_ola1, old, new demo_8 demo_18\n",
      "f_org_ola1, old, new demo_9 demo_19\n",
      "f_org_ola2, old, new demo_0 demo_20\n",
      "f_org_ola2, old, new demo_1 demo_21\n",
      "f_org_ola2, old, new demo_10 demo_22\n",
      "f_org_ola2, old, new demo_11 demo_23\n",
      "f_org_ola2, old, new demo_12 demo_24\n",
      "f_org_ola2, old, new demo_13 demo_25\n",
      "f_org_ola2, old, new demo_14 demo_26\n",
      "f_org_ola2, old, new demo_15 demo_27\n",
      "f_org_ola2, old, new demo_16 demo_28\n",
      "f_org_ola2, old, new demo_17 demo_29\n",
      "f_org_ola2, old, new demo_18 demo_30\n",
      "f_org_ola2, old, new demo_19 demo_31\n",
      "f_org_ola2, old, new demo_2 demo_32\n",
      "f_org_ola2, old, new demo_3 demo_33\n",
      "f_org_ola2, old, new demo_4 demo_34\n",
      "f_org_ola2, old, new demo_5 demo_35\n",
      "f_org_ola2, old, new demo_6 demo_36\n",
      "f_org_ola2, old, new demo_7 demo_37\n",
      "f_org_ola2, old, new demo_8 demo_38\n",
      "f_org_ola2, old, new demo_9 demo_39\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(output_path, \"w\") as f_new:\n",
    "    # Create the data group in the new dataset\n",
    "    data_group = f_new.create_group(\"data\")\n",
    "    demo_counter = 0  # Start numbering from 0\n",
    "    \n",
    "    \n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_ola1['data']:\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"f_org_ola1, old, new\", demo_name, new_demo_name)\n",
    "        demo=f_org_ola1['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "        \n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_ola2['data']:\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"f_org_ola2, old, new\", demo_name, new_demo_name)\n",
    "        demo=f_org_ola2['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_org_ola1, old, new demo_0 demo_0\n",
      "f_org_ola1, old, new demo_1 demo_1\n",
      "f_org_ola1, old, new demo_10 demo_2\n",
      "f_org_ola1, old, new demo_11 demo_3\n",
      "f_org_ola1, old, new demo_12 demo_4\n",
      "f_org_ola1, old, new demo_13 demo_5\n",
      "f_org_ola1, old, new demo_14 demo_6\n",
      "f_org_ola1, old, new demo_15 demo_7\n",
      "f_org_ola1, old, new demo_16 demo_8\n",
      "f_org_ola1, old, new demo_17 demo_9\n",
      "f_org_ola1, old, new demo_18 demo_10\n",
      "f_org_ola1, old, new demo_19 demo_11\n",
      "f_org_ola1, old, new demo_2 demo_12\n",
      "f_org_ola1, old, new demo_20 demo_13\n",
      "f_org_ola1, old, new demo_21 demo_14\n",
      "f_org_ola1, old, new demo_22 demo_15\n",
      "f_org_ola1, old, new demo_23 demo_16\n",
      "f_org_ola1, old, new demo_24 demo_17\n",
      "f_org_ola1, old, new demo_25 demo_18\n",
      "f_org_ola1, old, new demo_26 demo_19\n",
      "f_org_ola1, old, new demo_27 demo_20\n",
      "f_org_ola1, old, new demo_28 demo_21\n",
      "f_org_ola1, old, new demo_29 demo_22\n",
      "f_org_ola1, old, new demo_3 demo_23\n",
      "f_org_ola1, old, new demo_30 demo_24\n",
      "f_org_ola1, old, new demo_31 demo_25\n",
      "f_org_ola1, old, new demo_32 demo_26\n",
      "f_org_ola1, old, new demo_33 demo_27\n",
      "f_org_ola1, old, new demo_34 demo_28\n",
      "f_org_ola1, old, new demo_35 demo_29\n",
      "f_org_ola1, old, new demo_36 demo_30\n",
      "f_org_ola1, old, new demo_37 demo_31\n",
      "f_org_ola1, old, new demo_38 demo_32\n",
      "f_org_ola1, old, new demo_39 demo_33\n",
      "f_org_ola1, old, new demo_4 demo_34\n",
      "f_org_ola1, old, new demo_5 demo_35\n",
      "f_org_ola1, old, new demo_6 demo_36\n",
      "f_org_ola1, old, new demo_7 demo_37\n",
      "f_org_ola1, old, new demo_8 demo_38\n",
      "f_org_ola1, old, new demo_9 demo_39\n",
      "f_org_ola2, old, new demo_0 demo_40\n",
      "f_org_ola2, old, new demo_1 demo_41\n",
      "f_org_ola2, old, new demo_10 demo_42\n",
      "f_org_ola2, old, new demo_11 demo_43\n",
      "f_org_ola2, old, new demo_12 demo_44\n",
      "f_org_ola2, old, new demo_13 demo_45\n",
      "f_org_ola2, old, new demo_14 demo_46\n",
      "f_org_ola2, old, new demo_15 demo_47\n",
      "f_org_ola2, old, new demo_16 demo_48\n",
      "f_org_ola2, old, new demo_17 demo_49\n",
      "f_org_ola2, old, new demo_18 demo_50\n",
      "f_org_ola2, old, new demo_19 demo_51\n",
      "f_org_ola2, old, new demo_2 demo_52\n",
      "f_org_ola2, old, new demo_3 demo_53\n",
      "f_org_ola2, old, new demo_4 demo_54\n",
      "f_org_ola2, old, new demo_5 demo_55\n",
      "f_org_ola2, old, new demo_6 demo_56\n",
      "f_org_ola2, old, new demo_7 demo_57\n",
      "f_org_ola2, old, new demo_8 demo_58\n",
      "f_org_ola2, old, new demo_9 demo_59\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/home/carl_lab/data_franka/60_drawer_bellpepper.hdf5\"\n",
    "\n",
    "dataset_path_ola40_1 = \"/home/carl_lab/data_franka/40_drawer_bellpepper.hdf5\"\n",
    "f_org_ola1 = h5py.File(dataset_path_ola40_1, \"r\")\n",
    "\n",
    "dataset_path_ola40_2 = \"/home/carl_lab/data_franka/20_drawer_bellpepper_ns.hdf5\"\n",
    "f_org_ola2 = h5py.File(dataset_path_ola40_2, \"r\")\n",
    "\n",
    "\n",
    "with h5py.File(output_path, \"w\") as f_new:\n",
    "    # Create the data group in the new dataset\n",
    "    data_group = f_new.create_group(\"data\") \n",
    "    demo_counter = 0  # Start numbering from 0\n",
    "    \n",
    "    \n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_ola1['data']:\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"f_org_ola1, old, new\", demo_name, new_demo_name)\n",
    "        demo=f_org_ola1['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "        \n",
    "    # Copy all demonstrations from ola\n",
    "    for demo_name in f_org_ola2['data']:\n",
    "        new_demo_name = f\"demo_{demo_counter}\"\n",
    "        print(\"f_org_ola2, old, new\", demo_name, new_demo_name)\n",
    "        demo=f_org_ola2['data'][demo_name]  \n",
    "        new_demo=f_new[\"data\"].create_group(new_demo_name) \n",
    "        copy_group(demo, new_demo) \n",
    "        demo_counter += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
