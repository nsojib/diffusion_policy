{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Sequence, Dict, Union, Optional, Callable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiLM(nn.Module):\n",
    "    def __init__(self, out_channels, cond_dim):\n",
    "        super().__init__()\n",
    "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
    "        # predicts per-channel scale and bias\n",
    "        cond_channels = out_channels * 2\n",
    "        self.out_channels = out_channels\n",
    "        self.cond_encoder = nn.Sequential(\n",
    "            nn.Mish(),\n",
    "            nn.Linear(cond_dim, cond_channels),\n",
    "            nn.Unflatten(-1, (-1, 1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        embed = self.cond_encoder(cond)\n",
    "\n",
    "        embed = embed.reshape(\n",
    "            embed.shape[0], 2, self.out_channels, 1)\n",
    "        scale = embed[:,0,...]\n",
    "        bias = embed[:,1,...]\n",
    "        out = scale * x + bias    # FiLM modulation\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dBlock(nn.Module):\n",
    "    '''\n",
    "        Conv1d --> GroupNorm --> Mish\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondBlock1D(nn.Module):\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            cond_dim,\n",
    "            kernel_size=3,\n",
    "            n_groups=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "        self.gn1 = nn.GroupNorm(n_groups, out_channels)\n",
    "        self.gn2 = nn.GroupNorm(n_groups, out_channels) \n",
    "        self.film = FiLM(out_channels, cond_dim)  \n",
    "        \n",
    "    def forward(self, x, cond): \n",
    "        \"\"\" \n",
    "        Take input and condition, apply FiLM and return output\n",
    "        \"\"\"\n",
    "        x = self.conv1(x) \n",
    "        x = F.mish(  self.gn1(x) ) \n",
    "        \n",
    "        x = self.film(x, cond)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.mish(  self.gn2(x) ) \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownModule(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, cond_dim, kernel_size, n_groups, is_last=False):\n",
    "        super().__init__()\n",
    "        self.crb=CondBlock1D(\n",
    "                    dim_in, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups) \n",
    "        if is_last:\n",
    "            self.downsample = nn.Identity()\n",
    "        else: \n",
    "            self.downsample  =  nn.Conv1d(dim_out, dim_out, 3, 2, 1)\n",
    " \n",
    "    def forward(self, x, cond):\n",
    "        x = self.crb(x, cond)\n",
    "        x_small = self.downsample(x)\n",
    "\n",
    "        return x, x_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpModule(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, cond_dim, kernel_size, n_groups, is_last=False):\n",
    "        super().__init__()\n",
    "        if is_last:\n",
    "            self.upsample = nn.Identity()\n",
    "        else: \n",
    "            self.upsample = nn.ConvTranspose1d(dim_out, dim_out, 4, 2, 1)\n",
    "    \n",
    "        self.crb = CondBlock1D(\n",
    "                    dim_in, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups) \n",
    "\n",
    "    def forward(self, x, x_down, cond):\n",
    "        x = torch.cat((x, x_down), dim=1)    #unet skip connection\n",
    "        x = self.crb(x, cond)\n",
    "        x = self.upsample(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalUnet1D(nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim,\n",
    "        global_cond_dim,\n",
    "        diffusion_step_embed_dim=256,\n",
    "        down_dims=[256,512,1024],\n",
    "        kernel_size=5,\n",
    "        n_groups=8\n",
    "        ):\n",
    "        \"\"\"\n",
    "        input_dim: Dim of actions.\n",
    "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
    "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
    "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
    "        down_dims: Channel size for each UNet level.\n",
    "          The length of this array determines numebr of levels.\n",
    "        kernel_size: Conv kernel size\n",
    "        n_groups: Number of groups for GroupNorm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        all_dims = [input_dim] + list(down_dims)\n",
    "        start_dim = down_dims[0]\n",
    "\n",
    "        dsed = diffusion_step_embed_dim\n",
    "        diffusion_step_encoder = nn.Sequential(\n",
    "            SinusoidalPosEmb(dsed),\n",
    "            nn.Linear(dsed, dsed * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dsed * 4, dsed),\n",
    "        )\n",
    "        cond_dim = dsed + global_cond_dim\n",
    "\n",
    "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
    "        mid_dim = all_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList([\n",
    "            CondBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ), \n",
    "        ])\n",
    "\n",
    "        down_modules = nn.ModuleList([])  \n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            down_modules.append(\n",
    "                DownModule(dim_in, dim_out, cond_dim, kernel_size, n_groups, is_last)\n",
    "            )  \n",
    "\n",
    "        up_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            up_modules.append(\n",
    "                UpModule(dim_out*2, dim_in, cond_dim, kernel_size, n_groups, is_last)\n",
    "            )  \n",
    "\n",
    "        final_conv = nn.Sequential(\n",
    "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
    "            nn.Conv1d(start_dim, input_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.diffusion_step_encoder = diffusion_step_encoder\n",
    "        self.up_modules = up_modules\n",
    "        self.down_modules = down_modules\n",
    "        self.final_conv = final_conv \n",
    "\n",
    " \n",
    "    def forward(self,\n",
    "            sample: torch.Tensor,\n",
    "            timestep: Union[torch.Tensor, float, int],\n",
    "            global_cond=None):\n",
    "        \"\"\"\n",
    "        x: (B,T,input_dim)\n",
    "        timestep: (B,) or int, diffusion step\n",
    "        global_cond: (B,global_cond_dim)\n",
    "        output: (B,T,input_dim)\n",
    "        \"\"\"\n",
    "        # (B,T,C)\n",
    "        sample = sample.moveaxis(-1,-2)  # (B,C,T)\n",
    "\n",
    "        # 1. time \n",
    "        timestep  = timestep.expand(sample.shape[0]) \n",
    "        positional_feature = self.diffusion_step_encoder(timestep)\n",
    "\n",
    "        global_feature = torch.cat([positional_feature, global_cond], axis=-1)\n",
    "\n",
    "        # unet training\n",
    "        x = sample\n",
    "        h = []\n",
    "        for idx, down_module in enumerate(self.down_modules):\n",
    "            x, x_small = down_module(x, global_feature) \n",
    "            h.append(x)\n",
    "            x = x_small \n",
    "\n",
    "        for mid_module in self.mid_modules:\n",
    "            x = mid_module(x, global_feature)\n",
    "\n",
    "        for idx, upmodule  in enumerate(self.up_modules):\n",
    "            x= upmodule(x, h.pop(), global_feature) \n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # (B,C,T)\n",
    "        x = x.moveaxis(-1,-2)\n",
    "        # (B,T,C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_feature_dim = 512\n",
    "lowdim_obs_dim = 2\n",
    "obs_dim = vision_feature_dim + lowdim_obs_dim\n",
    "action_dim = 2\n",
    "obs_horizon = 2\n",
    "action_horizon=16\n",
    "noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 16, 2]), torch.Size([64]), torch.Size([64, 1028]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=64\n",
    "T=100\n",
    "obs_cond_dim = 1028\n",
    "\n",
    "noisy_actions = torch.randn(B,action_horizon,action_dim) \n",
    "timesteps = torch.randint(0, T,(B,)).long()\n",
    "obs_cond = torch.randn(B,obs_cond_dim)\n",
    "\n",
    "noisy_actions.shape, timesteps.shape, obs_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_pred = noise_pred_net(noisy_actions, timesteps, global_cond=obs_cond)\n",
    "noise_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConditionalUnet1D(\n",
       "  (mid_modules): ModuleList(\n",
       "    (0): CondBlock1D(\n",
       "      (conv1): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (conv2): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (gn1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "      (gn2): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "      (film): FiLM(\n",
       "        (cond_encoder): Sequential(\n",
       "          (0): Mish()\n",
       "          (1): Linear(in_features=1284, out_features=2048, bias=True)\n",
       "          (2): Unflatten(dim=-1, unflattened_size=(-1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (diffusion_step_encoder): Sequential(\n",
       "    (0): SinusoidalPosEmb()\n",
       "    (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (2): Mish()\n",
       "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  )\n",
       "  (up_modules): ModuleList(\n",
       "    (0): UpModule(\n",
       "      (upsample): ConvTranspose1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (crb): CondBlock1D(\n",
       "        (conv1): Conv1d(2048, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (gn1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (gn2): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (film): FiLM(\n",
       "          (cond_encoder): Sequential(\n",
       "            (0): Mish()\n",
       "            (1): Linear(in_features=1284, out_features=1024, bias=True)\n",
       "            (2): Unflatten(dim=-1, unflattened_size=(-1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): UpModule(\n",
       "      (upsample): ConvTranspose1d(256, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (crb): CondBlock1D(\n",
       "        (conv1): Conv1d(1024, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (gn1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (gn2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (film): FiLM(\n",
       "          (cond_encoder): Sequential(\n",
       "            (0): Mish()\n",
       "            (1): Linear(in_features=1284, out_features=512, bias=True)\n",
       "            (2): Unflatten(dim=-1, unflattened_size=(-1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_modules): ModuleList(\n",
       "    (0): DownModule(\n",
       "      (crb): CondBlock1D(\n",
       "        (conv1): Conv1d(2, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (gn1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (gn2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (film): FiLM(\n",
       "          (cond_encoder): Sequential(\n",
       "            (0): Mish()\n",
       "            (1): Linear(in_features=1284, out_features=512, bias=True)\n",
       "            (2): Unflatten(dim=-1, unflattened_size=(-1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    )\n",
       "    (1): DownModule(\n",
       "      (crb): CondBlock1D(\n",
       "        (conv1): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (gn1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (gn2): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (film): FiLM(\n",
       "          (cond_encoder): Sequential(\n",
       "            (0): Mish()\n",
       "            (1): Linear(in_features=1284, out_features=1024, bias=True)\n",
       "            (2): Unflatten(dim=-1, unflattened_size=(-1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    )\n",
       "    (2): DownModule(\n",
       "      (crb): CondBlock1D(\n",
       "        (conv1): Conv1d(512, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (conv2): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (gn1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "        (gn2): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "        (film): FiLM(\n",
       "          (cond_encoder): Sequential(\n",
       "            (0): Mish()\n",
       "            (1): Linear(in_features=1284, out_features=2048, bias=True)\n",
       "            (2): Unflatten(dim=-1, unflattened_size=(-1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): Identity()\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Sequential(\n",
       "    (0): Conv1dBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (2): Mish()\n",
       "      )\n",
       "    )\n",
       "    (1): Conv1d(256, 2, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_pred_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
